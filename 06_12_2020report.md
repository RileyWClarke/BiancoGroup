# Riley Clarke - Week of 06/12/2020

## 1. 

### 1.1 Papers Read

<https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c/>: A One-Stop Shop for Principal Component Analysis

In this article, the author nicely summmarizes some simple questions about Principle Component Analysis (PCA), such as "What is PCA?", "When Should I Use PCA?", "How & Why Does PCA Work?". Some details I found interesting and took mental note of were that you should be comfortable making your independent variable less interpretable if you decide to use PCA, that the eigenvectors and eigenvalues of the covariance matrix extracted by the algorithm can be interpreted as, respectively, the direction and relative importance of each direction of your n-dimensional dataset, and that the reason PCA is so useful is that the more variability there is in a particular direction, the more likely one is to find signal rather than noise in that direction. This gives us insight as to whcih features in the data are unimportant and can be dropped to reduce dimensionality of the data.

### 1.2 Code Written

fftfiltering2.ipynb: Added .csv table of the K2 Variability Catalog (https://archive.stsci.edu/prepds/k2varcat/). 
This catalog includes the following columns:\
EPIC ID\
Campaign Number\
Most Likely Class (class with highest probability)\
Prob. of Delta Scuti Class\
Prob. of Detached Eclipsing Binary (EA) Class\
Prob. of Semi-Detached/Contact Eclipsing Binary (EB) Class\
Prob. of Gamma Dor Class\
Prob. of Non-Variable (NOISE) Class\
Prob. of Other Periodic/Quasi-Periodic (OTHPER) Class\
Prob. of RR Lyrae ab Class\
Anomaly Score (higher score = not well-described by training set, i.e., likely outlier)\

Used ID # and Campaign # from table to create list of URLs to read in via astropy.fits. 
Wrote function to read in URLs by Campaign #, truncated initial data gap in each series.
Made histogram of gap widths in flux series.

Link: https://github.com/RileyWClarke/BiancoGroup/blob/master/Notebooks/fftfilter2.ipynb

## 2. Figures

![](Figures/nanseries.png?raw=true)

Figure 1: Every 100th lightcurve in the 974 obtained from K2VARCAT. Note that all lightcurves have the same characteristic data gap at first, likely due to them being from K2's inaugural campaign. 

![](Figures/nanhist.png?raw=true)

Figure 2: Distribution of length of consecutive NaN elements in all 974 flux arrays. 

Figure code: https://github.com/RileyWClarke/BiancoGroup/blob/master/Notebooks/fftfilter2.ipynb

## 3 Results & Future Goals

### 3.1 Results

Reading in URLs obtained from K2VARCAT is more efficient than trying 1000s of random urls, but still time-consuming, so only reading in sample of 974 light curves. This lightcurves have no data/zero flux for the first ~40 days, so I cut out these empty regions. The leftover lightcurves still contain NaNs, however the gaps are small, and most are only 1 NaN wide, so linearly interpolating the gaps is viable. 

### 3.2 Goals

-Linearly interpolate NaNs in each series (Tentative delivery: 6/15)
-Make power spectra for each campaign
-Create class: lightcurve, define functions to pull flux & time, create power spectra
-Run PCA on PS from single campaign, all campaigns, highest SNR targets (tentative)
